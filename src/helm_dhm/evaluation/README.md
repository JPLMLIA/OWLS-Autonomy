# Evaluation

The functionality here is meant to help make simple performance estimates using
predicted tracks (e.g., from `tracker.py`) and ground truth tracks (e.g., from a
simulator).

See `point_metrics.py` for calculation of metrics given track points and
`reporting.py` for available functions to calculate bathes of metrics and
(eventually) generate plots.